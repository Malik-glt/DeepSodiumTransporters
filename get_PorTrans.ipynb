{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77fed536-a5eb-418c-8519-804206e2bc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from transformers import T5EncoderModel, T5Tokenizer\n",
    "import torch\n",
    "import h5py\n",
    "import time\n",
    "import argparse\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44ac6727-ace7-46f3-b8a9-d421f21af40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "\n",
    "        self.elmo_feature_extractor = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(1024, 32, kernel_size=(7, 1), padding=(3, 0)),  # 7x32\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(0.25),\n",
    "        )\n",
    "        n_final_in = 32\n",
    "        self.dssp3_classifier = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(n_final_in, 3, kernel_size=(7, 1), padding=(3, 0))  # 7\n",
    "        )\n",
    "\n",
    "        self.dssp8_classifier = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(n_final_in, 8, kernel_size=(7, 1), padding=(3, 0))\n",
    "        )\n",
    "        self.diso_classifier = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(n_final_in, 2, kernel_size=(7, 1), padding=(3, 0))\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # IN: X = (B x L x F); OUT: (B x F x L, 1)\n",
    "        x = x.permute(0, 2, 1).unsqueeze(dim=-1)\n",
    "        x = self.elmo_feature_extractor(x)  # OUT: (B x 32 x L x 1)\n",
    "        d3_Yhat = self.dssp3_classifier(x).squeeze(dim=-1).permute(0, 2, 1)  # OUT: (B x L x 3)\n",
    "        d8_Yhat = self.dssp8_classifier(x).squeeze(dim=-1).permute(0, 2, 1)  # OUT: (B x L x 8)\n",
    "        diso_Yhat = self.diso_classifier(x).squeeze(dim=-1).permute(0, 2, 1)  # OUT: (B x L x 2)\n",
    "        return d3_Yhat, d8_Yhat, diso_Yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "417ab3e5-e091-4152-9ec6-2e495888bd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sec_struct_model():\n",
    "    checkpoint_dir = \"D:/htchang/DPCR/Data/PortTrans/protT5/sec_struct_checkpoint/secstruct_checkpoint.pt\"\n",
    "    state = torch.load(checkpoint_dir)\n",
    "    model = ConvNet()\n",
    "    model.load_state_dict(state['state_dict'])\n",
    "    model = model.eval()\n",
    "    model = model.to(device)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e659874-f67b-4eff-b712-8f542442f0dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi there\n"
     ]
    }
   ],
   "source": [
    "def read_fasta(fasta_path, split_char=\"!\", id_field=0):\n",
    "    seq = ''\n",
    "    with open(fasta_path, 'r') as fasta_f:\n",
    "        for line in fasta_f:\n",
    "            if not line.startswith('>'):\n",
    "                seq += line.strip()\n",
    "\n",
    "    seq_id = os.path.splitext(os.path.basename(fasta_path))[0] # Get only the file name without path and extension\n",
    "    seqs = [(seq_id, seq)]\n",
    "\n",
    "    return seqs\n",
    "print(\"hi there\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74809e14-9d53-434e-8abb-16d8da99b437",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_T5_model():\n",
    "    model = T5EncoderModel.from_pretrained(\"Rostlab/prot_t5_xl_half_uniref50-enc\")\n",
    "    # Rostlab/prot_t5_xl_uniref50\n",
    "    model = model.to(device)  # move model to GPU\n",
    "    model = model.eval()  # set model to evaluation model\n",
    "    tokenizer = T5Tokenizer.from_pretrained('Rostlab/prot_t5_xl_half_uniref50-enc', do_lower_case=False)\n",
    "\n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9527982-750b-4b11-b8ed-407aae485095",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(model, tokenizer, seqs, max_residues=4000, max_seq_len=1000, max_batch=100):\n",
    "    results = {\"residue_embs\": dict()}\n",
    "\n",
    "    # sort sequences according to length (reduces unnecessary padding --> speeds up embedding)\n",
    "    seq_dict = sorted(seqs, key=lambda x: len(x[1]), reverse=True)\n",
    "    start = time.time()\n",
    "    batch = []\n",
    "\n",
    "    for seq_idx, (pdb_id, seq) in enumerate(seq_dict, 1):\n",
    "        seq_len = len(seq)\n",
    "        seq = ' '.join(list(seq))\n",
    "        batch.append((pdb_id, seq, seq_len))\n",
    "\n",
    "        # count residues in current batch and add the last sequence length to\n",
    "        # avoid that batches with (n_res_batch > max_residues) get processed\n",
    "        n_res_batch = sum([s_len for _, _, s_len in batch]) + seq_len\n",
    "        if len(batch) >= max_batch or n_res_batch >= max_residues or seq_idx == len(seq_dict) or seq_len > max_seq_len:\n",
    "            pdb_ids, seqs, seq_lens = zip(*batch)\n",
    "            batch = []\n",
    "\n",
    "            # add_special_tokens adds extra token at the end of each sequence\n",
    "            token_encoding = tokenizer.batch_encode_plus(seqs, add_special_tokens=True, padding=\"longest\")\n",
    "            input_ids = torch.tensor(token_encoding['input_ids']).to(device)\n",
    "            attention_mask = torch.tensor(token_encoding['attention_mask']).to(device)\n",
    "\n",
    "            try:\n",
    "                with torch.no_grad():\n",
    "                    # returns: ( batch-size x max_seq_len_in_minibatch x embedding_dim )\n",
    "                    embedding_repr = model(input_ids, attention_mask=attention_mask)\n",
    "            except RuntimeError:\n",
    "                print(\"RuntimeError during embedding for {} (L={})\".format(pdb_id, seq_len))\n",
    "                continue\n",
    "\n",
    "            for batch_idx, identifier in enumerate(pdb_ids):  # for each protein in the current mini-batch\n",
    "                s_len = seq_lens[batch_idx]\n",
    "                # slice off padding --> batch-size x seq_len x embedding_dim\n",
    "                emb = embedding_repr.last_hidden_state[batch_idx, :s_len]\n",
    "                if \"residue_embs\" in results:\n",
    "                    results[\"residue_embs\"][identifier] = emb.detach().cpu().numpy().squeeze()\n",
    "\n",
    "    passed_time = time.time() - start\n",
    "    avg_time = passed_time / len(results[\"residue_embs\"])\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba46fdac-c7cb-47c8-8225-c64bd4f8a6ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Using {}\".format(device))\n",
    "model, tokenizer = get_T5_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b875174-18d6-43a1-90b2-3253d3efb3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_port_map(port_data,output_file):\n",
    "    np.savetxt(output_file, port_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0710ab6-ceab-4ea1-973f-ef8dd7c74978",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def main(input_folder=\"D:/Malik/SATs/Sugar vs others/Dataset\", output_folder=\"D:/Malik/SATs/Sugar vs others/Prottrans\"):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    for data_folder in [\"Other SATs\", \"Sugar\"]:\n",
    "        data_folder_path = os.path.join(input_folder, data_folder)\n",
    "        output_data_folder_path = os.path.join(output_folder, data_folder)\n",
    "        os.makedirs(output_data_folder_path, exist_ok=True)\n",
    "\n",
    "        for folder_name in [\"Train\", \"Test\"]:\n",
    "            input_folder_path = os.path.join(data_folder_path, folder_name)\n",
    "            output_folder_path = os.path.join(output_data_folder_path, folder_name)\n",
    "            os.makedirs(output_folder_path, exist_ok=True)\n",
    "\n",
    "            for file_name in os.listdir(input_folder_path):\n",
    "                fasta_file = os.path.join(input_folder_path, file_name)\n",
    "                output_file = os.path.join(output_folder_path, file_name)\n",
    "\n",
    "                # Generate PortTran features here using your existing code\n",
    "                filename = os.path.splitext(os.path.basename(fasta_file))[0]\n",
    "                seqs = read_fasta(fasta_file)\n",
    "                results = get_embeddings(model, tokenizer, seqs)\n",
    "                embeddings = results['residue_embs'][filename]\n",
    "\n",
    "                # Save the PortTran features to the output file\n",
    "                save_port_map(embeddings, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30cc50ee-9295-41c7-b8b7-c3265e2acb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f67b74-2415-4f5e-8171-b2f0660e6bd2",
   "metadata": {},
   "source": [
    "## For SLC Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4ffff3d-e37f-49c3-8156-78fe0151e3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Define your read_fasta, get_embeddings, and save_port_map functions here\n",
    "\n",
    "def main(input_folder=\"D:/Malik/SATs/SLC_Data\", output_folder=\"D:/Malik/SATs/Amino acid vs others/Prottrans/SLC\"):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Iterate over the folders in the input dataset\n",
    "    for data_folder in [\"Amino acid\", \"Sodium\", \"Sugar\"]:\n",
    "        data_folder_path = os.path.join(input_folder, data_folder)\n",
    "        output_data_folder_path = os.path.join(output_folder, data_folder)\n",
    "        os.makedirs(output_data_folder_path, exist_ok=True)\n",
    "\n",
    "        # Iterate over files in the input folder\n",
    "        for file_name in os.listdir(data_folder_path):\n",
    "            fasta_file = os.path.join(data_folder_path, file_name)\n",
    "            output_file = os.path.join(output_data_folder_path, file_name)\n",
    "\n",
    "            # Generate ProtTrans embeddings here\n",
    "            filename = os.path.splitext(os.path.basename(fasta_file))[0]\n",
    "            \n",
    "            # Implement read_fasta function\n",
    "            seqs = read_fasta(fasta_file)\n",
    "\n",
    "            # Implement get_embeddings function\n",
    "            results = get_embeddings(model, tokenizer, seqs)\n",
    "            embeddings = results['residue_embs'][filename]\n",
    "\n",
    "            # Implement save_port_map function\n",
    "            save_port_map(embeddings, output_file)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf4e6aeb-c318-434b-9e32-d630b6ed84d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data Spliting\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil\n",
    "\n",
    "def split_data(input_folder, output_train_folder, output_test_folder, test_size=0.2, random_state=42):\n",
    "    # Create output folders if they don't exist\n",
    "    os.makedirs(output_train_folder, exist_ok=True)\n",
    "    os.makedirs(output_test_folder, exist_ok=True)\n",
    "\n",
    "    # List all files in the input folder\n",
    "    files = os.listdir(input_folder)\n",
    "\n",
    "    # Split the files into training and testing sets\n",
    "    train_files, test_files = train_test_split(files, test_size=test_size, random_state=random_state)\n",
    "\n",
    "    # Move files to the corresponding output folders\n",
    "    for file in train_files:\n",
    "        source_path = os.path.join(input_folder, file)\n",
    "        destination_path = os.path.join(output_train_folder, file)\n",
    "        shutil.copyfile(source_path, destination_path)\n",
    "\n",
    "    for file in test_files:\n",
    "        source_path = os.path.join(input_folder, file)\n",
    "        destination_path = os.path.join(output_test_folder, file)\n",
    "        shutil.copyfile(source_path, destination_path)\n",
    "\n",
    "# Replace these paths with your actual folder paths\n",
    "amino_acids_folder = 'D:/Malik/SATs/Complete Data/Sugar vs Other/Sugar'\n",
    "other_folder = 'D:/Malik/SATs/Complete Data/Sugar vs Other/Other'\n",
    "\n",
    "train_amino_acids_folder = 'D:/Malik/SATs/Sugar vs others/Dataset/Sugar/Train'\n",
    "test_amino_acids_folder = 'D:/Malik/SATs/Sugar vs others/Dataset/Sugar/Test'\n",
    "\n",
    "train_other_folder = 'D:/Malik/SATs/Sugar vs others/Dataset/Other/Train'\n",
    "test_other_folder = 'D:/Malik/SATs/Sugar vs others/Dataset/Other/Test'\n",
    "\n",
    "# Split data for amino acids folder\n",
    "split_data(amino_acids_folder, train_amino_acids_folder, test_amino_acids_folder)\n",
    "\n",
    "# Split data for other folder\n",
    "split_data(other_folder, train_other_folder, test_other_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7dbc80-25c5-4a5a-84ec-b080ddee440c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of FastA files in 'D:/Malik/SATs/Amino acid vs others/Dataset/Other SATs/Train': 318\n",
      "List of FastA files:\n",
      "A0A3Q7ZPG5.fasta\n",
      "A0A494BA31.fasta\n",
      "A0AV02.fasta\n",
      "A0PJK1.fasta\n",
      "A2ARP9.fasta\n",
      "A8MYU2.fasta\n",
      "B2RXE2.fasta\n",
      "D3Z291.fasta\n",
      "D3ZJ86.fasta\n",
      "D4AD53.fasta\n",
      "E7FKV8.fasta\n",
      "E9PQ53.fasta\n",
      "E9Q3M5.fasta\n",
      "G3X943.fasta\n",
      "H1AFJ5.fasta\n",
      "O00180.fasta\n",
      "O00476.fasta\n",
      "O00555.fasta\n",
      "O08962.fasta\n",
      "O13001.fasta\n",
      "O14569.fasta\n",
      "O14949.fasta\n",
      "O14957.fasta\n",
      "O15239.fasta\n",
      "O35119.fasta\n",
      "O35174.fasta\n",
      "O35240.fasta\n",
      "O35316.fasta\n",
      "O35458.fasta\n",
      "O35526.fasta\n",
      "O43497.fasta\n",
      "O43526.fasta\n",
      "O43826.fasta\n",
      "O43920.fasta\n",
      "O54982.fasta\n",
      "O55143.fasta\n",
      "O55192.fasta\n",
      "O60721.fasta\n",
      "O60928.fasta\n",
      "O70578.fasta\n",
      "O70594.fasta\n",
      "O75185.fasta\n",
      "O88427.fasta\n",
      "O88454.fasta\n",
      "O88457.fasta\n",
      "O88602.fasta\n",
      "O88704.fasta\n",
      "O88944.fasta\n",
      "O95069.fasta\n",
      "O95139.fasta\n",
      "O95167.fasta\n",
      "O95168.fasta\n",
      "O95182.fasta\n",
      "O95259.fasta\n",
      "O95528.fasta\n",
      "P00158.fasta\n",
      "P00174.fasta\n",
      "P03891.fasta\n",
      "P03892.fasta\n",
      "P03893.fasta\n",
      "P03899.fasta\n",
      "P03903.fasta\n",
      "P03905.fasta\n",
      "P03911.fasta\n",
      "P03915.fasta\n",
      "P03920.fasta\n",
      "P03921.fasta\n",
      "P03923.fasta\n",
      "P03924.fasta\n",
      "P05029.fasta\n",
      "P07293.fasta\n",
      "P08104.fasta\n",
      "P08251.fasta\n",
      "P0DMA5.fasta\n",
      "P10897.fasta\n",
      "P11506.fasta\n",
      "P13498.fasta\n",
      "P14142.fasta\n",
      "P14927.fasta\n",
      "P15381.fasta\n",
      "P15383.fasta\n",
      "P15389.fasta\n",
      "P17568.fasta\n",
      "P17659.fasta\n",
      "P19517.fasta\n",
      "P22001.fasta\n",
      "P23978.fasta\n",
      "P26431.fasta\n",
      "P27732.fasta\n",
      "P27799.fasta\n",
      "P27922.fasta\n",
      "P28570.fasta\n",
      "P29995.fasta\n",
      "P31637.fasta\n",
      "P31751.fasta\n",
      "P35670.fasta\n",
      "P43427.fasta\n",
      "P46408.fasta\n",
      "P48048.fasta\n",
      "P48543.fasta\n",
      "P48549.fasta\n",
      "P48995.fasta\n",
      "P50992.fasta\n",
      "P51167.fasta\n",
      "P51168.fasta\n",
      "P51169.fasta\n",
      "P51970.fasta\n",
      "P52190.fasta\n",
      "P54219.fasta\n",
      "P54707.fasta\n",
      "P54709.fasta\n",
      "P55019.fasta\n",
      "P57789.fasta\n",
      "P58295.fasta\n",
      "P60570.fasta\n",
      "P63161.fasta\n",
      "P70172.fasta\n",
      "P70452.fasta\n",
      "P70673.fasta\n",
      "P78348.fasta\n",
      "P78382.fasta\n",
      "P78508.fasta\n",
      "P97441.fasta\n",
      "P97445.fasta\n",
      "P97557.fasta\n",
      "P97794.fasta\n",
      "P98194.fasta\n",
      "Q00975.fasta\n",
      "Q01118.fasta\n",
      "Q01956.fasta\n",
      "Q02373.fasta\n",
      "Q02563.fasta\n",
      "Q02827.fasta\n",
      "Q03719.fasta\n",
      "Q04645.fasta\n",
      "Q04646.fasta\n",
      "Q04656.fasta\n",
      "Q05037.fasta\n",
      "Q07782.fasta\n",
      "Q08289.fasta\n",
      "Q08460.fasta\n",
      "Q08849.fasta\n",
      "Q0GE19.fasta\n",
      "Q12791.fasta\n",
      "Q13507.fasta\n",
      "Q13563.fasta\n",
      "Q13936.fasta\n",
      "Q14573.fasta\n",
      "Q14643.fasta\n",
      "Q14721.fasta\n",
      "Q14722.fasta\n",
      "Q14916.fasta\n",
      "Q15858.fasta\n",
      "Q16206.fasta\n",
      "Q16322.fasta\n",
      "Q16515.fasta\n",
      "Q16572.fasta\n",
      "Q16718.fasta\n",
      "Q27963.fasta\n",
      "Q28139.fasta\n",
      "Q28615.fasta\n",
      "Q2Y0W8.fasta\n",
      "Q3KNW5.fasta\n",
      "Q3TQB2.fasta\n",
      "Q3ZAS0.fasta\n",
      "Q3ZMH1.fasta\n",
      "Q496J9.fasta\n",
      "Q49B93.fasta\n",
      "Q5BJM8.fasta\n",
      "Q5BKR2.fasta\n",
      "Q5DTL9.fasta\n",
      "Q5IRJ6.fasta\n",
      "Q5J316.fasta\n",
      "Q5M848.fasta\n",
      "Q5SZA1.fasta\n",
      "Q5XHB4.fasta\n",
      "Q61180.fasta\n",
      "Q61983.fasta\n",
      "Q62720.fasta\n",
      "Q62897.fasta\n",
      "Q63564.fasta\n",
      "Q63633.fasta\n",
      "Q63881.fasta\n",
      "Q64568.fasta\n",
      "Q687X5.fasta\n",
      "Q6GN30.fasta\n",
      "Q6IVV8.fasta\n",
      "Q6P1H1.fasta\n",
      "Q6PHZ8.fasta\n",
      "Q6Q760.fasta\n",
      "Q6RX08.fasta\n",
      "Q6UJY2.fasta\n",
      "Q6UVM4.fasta\n",
      "Q6VV64.fasta\n",
      "Q6XR72.fasta\n",
      "Q708S6.fasta\n",
      "Q708S7.fasta\n",
      "Q7RTX7.fasta\n",
      "Q7T384.fasta\n",
      "Q7YRU6.fasta\n",
      "Q7Z418.fasta\n",
      "Q80SU6.fasta\n",
      "Q80T22.fasta\n",
      "Q80W99.fasta\n",
      "Q80YW5.fasta\n",
      "Q86UR5.fasta\n",
      "Q86Y39.fasta\n",
      "Q8BFU8.fasta\n",
      "Q8BLV3.fasta\n",
      "Q8BTY2.fasta\n",
      "Q8BUE1.fasta\n",
      "Q8BVN3.fasta\n",
      "Q8BWY7.fasta\n",
      "Q8BYF6.fasta\n",
      "Q8C0X2.fasta\n",
      "Q8C3K6.fasta\n",
      "Q8CIZ9.fasta\n",
      "Q8IWU4.fasta\n",
      "Q8IZK6.fasta\n",
      "Q8K211.fasta\n",
      "Q8K385.fasta\n",
      "Q8K424.fasta\n",
      "Q8N8Q1.fasta\n",
      "Q8NCC5.fasta\n",
      "Q8NCM2.fasta\n",
      "Q8NEC5.fasta\n",
      "Q8NFT2.fasta\n",
      "Q8NHX9.fasta\n",
      "Q8R426.fasta\n",
      "Q8R526.fasta\n",
      "Q8TAD4.fasta\n",
      "Q8TAE7.fasta\n",
      "Q8TC92.fasta\n",
      "Q8TDN1.fasta\n",
      "Q8TDX9.fasta\n",
      "Q8VHW2.fasta\n",
      "Q8VHW9.fasta\n",
      "Q8WWG9.fasta\n",
      "Q8WWX8.fasta\n",
      "Q91WD2.fasta\n",
      "Q91ZR5.fasta\n",
      "Q920L1.fasta\n",
      "Q921R7.fasta\n",
      "Q924N4.fasta\n",
      "Q925G2.fasta\n",
      "Q92953.fasta\n",
      "Q969S0.fasta\n",
      "Q96A29.fasta\n",
      "Q96AA3.fasta\n",
      "Q96AQ8.fasta\n",
      "Q96FT7.fasta\n",
      "Q96G79.fasta\n",
      "Q96H72.fasta\n",
      "Q96KK3.fasta\n",
      "Q96P56.fasta\n",
      "Q96QT4.fasta\n",
      "Q96T55.fasta\n",
      "Q99712.fasta\n",
      "Q99J21.fasta\n",
      "Q99K24.fasta\n",
      "Q99NE5.fasta\n",
      "Q9BQ31.fasta\n",
      "Q9BRI3.fasta\n",
      "Q9BRV3.fasta\n",
      "Q9BSA9.fasta\n",
      "Q9BSW2.fasta\n",
      "Q9BW72.fasta\n",
      "Q9BX84.fasta\n",
      "Q9BXT2.fasta\n",
      "Q9CQZ5.fasta\n",
      "Q9CQZ6.fasta\n",
      "Q9D8B4.fasta\n",
      "Q9DAV9.fasta\n",
      "Q9DEX7.fasta\n",
      "Q9EPK8.fasta\n",
      "Q9EQJ0.fasta\n",
      "Q9ERS0.fasta\n",
      "Q9ES08.fasta\n",
      "Q9H252.fasta\n",
      "Q9H3M0.fasta\n",
      "Q9H427.fasta\n",
      "Q9H6F2.fasta\n",
      "Q9HCF6.fasta\n",
      "Q9I9C3.fasta\n",
      "Q9JIS7.fasta\n",
      "Q9JJ69.fasta\n",
      "Q9JJV7.fasta\n",
      "Q9JJZ1.fasta\n",
      "Q9JK45.fasta\n",
      "Q9JKA8.fasta\n",
      "Q9JLJ1.fasta\n",
      "Q9JLR9.fasta\n",
      "Q9JM47.fasta\n",
      "Q9NPC2.fasta\n",
      "Q9NS40.fasta\n",
      "Q9NTN3.fasta\n",
      "Q9NY26.fasta\n",
      "Q9NY37.fasta\n",
      "Q9P0L9.fasta\n",
      "Q9QX29.fasta\n",
      "Q9R1N3.fasta\n",
      "Q9TU34.fasta\n",
      "Q9UGH3.fasta\n",
      "Q9UI09.fasta\n",
      "Q9UJ96.fasta\n",
      "Q9UL51.fasta\n",
      "Q9ULD8.fasta\n",
      "Q9UNX9.fasta\n",
      "Q9WU39.fasta\n",
      "Q9WV27.fasta\n",
      "Q9Y210.fasta\n",
      "Q9Y2C5.fasta\n",
      "Q9Y2E8.fasta\n",
      "Q9Y2W3.fasta\n",
      "Q9Y3Q4.fasta\n",
      "Q9Y5S1.fasta\n",
      "Q9Z258.fasta\n",
      "Q9Z307.fasta\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def count_fasta_files(folder_path):\n",
    "    # Ensure the provided path is a directory\n",
    "    if not os.path.isdir(folder_path):\n",
    "        print(f\"Error: '{folder_path}' is not a valid directory.\")\n",
    "        return None\n",
    "\n",
    "    # Get a list of files in the directory\n",
    "    files = os.listdir(folder_path)\n",
    "\n",
    "    # Count the number of files with the '.fasta' or '.fa' extension\n",
    "    fasta_files = [file for file in files if file.lower().endswith(('.fasta', '.fa'))]\n",
    "\n",
    "    # Print the count and list of FastA files\n",
    "    print(f\"Number of FastA files in '{folder_path}': {len(fasta_files)}\")\n",
    "    print(\"List of FastA files:\")\n",
    "    for file in fasta_files:\n",
    "        print(file)\n",
    "\n",
    "    return len(fasta_files)\n",
    "\n",
    "# Replace 'path_to_your_folder' with the actual path to your folder containing FastA files\n",
    "folder_path = 'D:/Malik/SATs/Amino acid vs others/Dataset/Other SATs/Train'\n",
    "\n",
    "# Call the function to count FastA files\n",
    "count = count_fasta_files(folder_path)\n",
    "\n",
    "# Optionally, use the count in your further processing or analysis\n",
    "if count is not None:\n",
    "    # Your additional code here\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2359b1d1-e2d8-49f0-a351-bfd54c651039",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
