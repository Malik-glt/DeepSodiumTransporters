{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "271c45cf-e40c-417c-a83e-03b375add143",
   "metadata": {},
   "source": [
    "# Implement Grad-CAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2df4e002-d1f8-4627-a755-5a325eda7ce9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "import os\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from time import gmtime, strftime\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, confusion_matrix, roc_auc_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers,Model\n",
    "from sklearn.model_selection import KFold\n",
    "import gc\n",
    "import time\n",
    "from sklearn.model_selection import KFold\n",
    "import import_test as data_load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "522add8c-0ba0-4fe3-87a0-45d7bcbf6f2a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "MAX_SEQ_LENGTH= 1100\n",
    "#NUM_FEATURE = 1024\n",
    "NUM_FEATURE = 1024 # esm1 & 2 a\n",
    "NUM_FILTER = 64\n",
    "NUM_HIDDEN = 512#100\n",
    "BATCH_SIZE  = 16\n",
    "WINDOW_SIZES = [4, 8, 16]\n",
    "NUM_CLASSES = 2\n",
    "CLASS_NAMES = ['1','0']\n",
    "EPOCHS      =15\n",
    "K_Fold = 5\n",
    "VALIDATION_MODE=\"independent\" # cross or independent\n",
    "class_names = [\"Sodium\", \"Membrane\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "286a7833-a705-42cc-a225-de9b9f9abe7a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/jupyter/Malik/SodiumTransporters/ProtTrans/All_Train_data.npy\n",
      "C:/jupyter/Malik/SodiumTransporters/ProtTrans/All_Train_labels.npy\n",
      "C:/jupyter/Malik/SodiumTransporters/ProtTrans/All_Test_data.npy\n",
      "C:/jupyter/Malik/SodiumTransporters/ProtTrans/All_Test_labels.npy\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "x_train,y_train,x_test,y_test= data_load.MCNN_data_load(NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5251a5a7-17b0-49ca-8794-7ba0dd850f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4638, 1, 1100, 1024)\n",
      "(4638, 2)\n",
      "(1161, 1, 1100, 1024)\n",
      "(1161, 2)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "30d3ef4d-db28-4030-97d4-d9873cb7a219",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, Model\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "class DeepScan(Model):\n",
    "    def __init__(self, window_sizes, num_filters, num_hidden, num_classes, model_input_shape=(None, None, 1024)):\n",
    "        super(DeepScan, self).__init__()\n",
    "        self.window_sizes = window_sizes\n",
    "        self.num_filters = num_filters\n",
    "        self.num_hidden = num_hidden\n",
    "        self.num_classes = num_classes\n",
    "        self._model_input_shape = model_input_shape\n",
    "        self.build_model()\n",
    "    \n",
    "    def build_model(self):\n",
    "        inputs = layers.Input(shape=self._model_input_shape, name='input_layer')\n",
    "        self.conv_outputs = []\n",
    "        \n",
    "        conv_outputs = []\n",
    "        for i, window_size in enumerate(self.window_sizes, start=1):\n",
    "            x = layers.Conv2D(\n",
    "                filters=self.num_filters,\n",
    "                kernel_size=(1, window_size),\n",
    "                activation='relu',\n",
    "                padding='valid',\n",
    "                kernel_initializer='glorot_uniform',\n",
    "                bias_initializer=tf.constant_initializer(0.1),\n",
    "                name=f'conv2d_{i}'\n",
    "            )(inputs)\n",
    "            \n",
    "            self.conv_outputs.append(x)\n",
    "            \n",
    "            x = layers.MaxPooling2D(\n",
    "                pool_size=(1, 2),\n",
    "                strides=(1, 1),\n",
    "                padding='valid',\n",
    "                name=f'max_pooling2d_{i}'\n",
    "            )(x)\n",
    "            \n",
    "            x = layers.GlobalAveragePooling2D(name=f'global_pool_{i}')(x)\n",
    "            conv_outputs.append(x)\n",
    "\n",
    "        x = layers.Concatenate(name=\"concatenate\")(conv_outputs)\n",
    "        x = layers.Dropout(rate=0.7)(x)\n",
    "        \n",
    "        x = layers.Dense(\n",
    "            self.num_hidden,\n",
    "            activation='relu',\n",
    "            kernel_initializer='glorot_uniform',\n",
    "            bias_initializer=tf.constant_initializer(0.1),\n",
    "            name='dense_1'\n",
    "        )(x)\n",
    "        \n",
    "        outputs = layers.Dense(\n",
    "            self.num_classes,\n",
    "            activation='softmax',\n",
    "            kernel_regularizer=tf.keras.regularizers.l2(1e-3),\n",
    "            name='dense_2'\n",
    "        )(x)\n",
    "        \n",
    "        self.model = Model(inputs=inputs, outputs=outputs, name='deepscan')\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        return self.model(inputs)\n",
    "    \n",
    "    def get_grad_cam_heatmap(self, x, class_index=None, layer_name='conv2d_1'):\n",
    "        \"\"\"\n",
    "        Computes Grad-CAM heatmap for the specified layer using TensorFlow operations.\n",
    "        \"\"\"\n",
    "        # Find target layer\n",
    "        target_layer = None\n",
    "        for layer in self.model.layers:\n",
    "            if layer.name == layer_name:\n",
    "                target_layer = layer\n",
    "                break\n",
    "                \n",
    "        if target_layer is None:\n",
    "            raise ValueError(f\"Layer {layer_name} not found in the model.\")\n",
    "        \n",
    "        # Create Grad-CAM model\n",
    "        grad_model = Model(\n",
    "            inputs=[self.model.inputs],\n",
    "            outputs=[target_layer.output, self.model.output]\n",
    "        )\n",
    "        \n",
    "        # Convert input to tensor if necessary\n",
    "        if not isinstance(x, tf.Tensor):\n",
    "            x = tf.convert_to_tensor(x)\n",
    "            \n",
    "        # Compute gradients using TensorFlow operations\n",
    "        with tf.GradientTape() as tape:\n",
    "            conv_output, predictions = grad_model(x)\n",
    "            if class_index is None:\n",
    "                class_index = tf.argmax(predictions[0])\n",
    "            class_channel = predictions[:, class_index]\n",
    "            \n",
    "        # Get gradients\n",
    "        grads = tape.gradient(class_channel, conv_output)\n",
    "        \n",
    "        # Compute weighted feature map using TF operations\n",
    "        pooled_grads = tf.reduce_mean(grads, axis=(1, 2))\n",
    "        weighted_conv_output = tf.multiply(conv_output[0], pooled_grads[0, :, None, None])\n",
    "        heatmap = tf.reduce_sum(weighted_conv_output, axis=-1)\n",
    "        \n",
    "        # ReLU and normalize\n",
    "        heatmap = tf.maximum(heatmap, 0)\n",
    "        max_val = tf.reduce_max(heatmap)\n",
    "        if max_val != 0:\n",
    "            heatmap = heatmap / max_val\n",
    "            \n",
    "        return heatmap.numpy()\n",
    "\n",
    "    def summary(self):\n",
    "        return self.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9ba31d-e01e-472f-8064-bdf4f22e27b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# Define the directories to save the heatmaps\n",
    "heatmap_save_dir = \"C:/jupyter/Malik/SodiumTransporters/Code/HeatMaps_All\"\n",
    "os.makedirs(f\"{heatmap_save_dir}/Positives\", exist_ok=True)\n",
    "os.makedirs(f\"{heatmap_save_dir}/Negatives\", exist_ok=True)\n",
    "\n",
    "# Load your data (replace these lines with actual loading logic)\n",
    "x_train = x_train  # Replace with actual data loading\n",
    "y_train = y_train\n",
    "x_test = x_test\n",
    "y_test = y_test\n",
    "\n",
    "# Initialize DataGenerator with training data\n",
    "generator = DataGenerator(\n",
    "    data=x_train,\n",
    "    labels=y_train,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "# Initialize DeepScan model\n",
    "model = DeepScan(\n",
    "    window_sizes=WINDOW_SIZES,  # Replace with actual window sizes\n",
    "    num_filters=NUM_FILTER,    # Replace with actual number of filters\n",
    "    num_hidden=NUM_HIDDEN,     # Replace with actual number of hidden units\n",
    "    num_classes=NUM_CLASSES,   # Replace with actual number of classes\n",
    "    model_input_shape=(1, 1100, 1024)\n",
    ")\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Print model summary\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    generator,\n",
    "    epochs=EPOCHS,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Function to generate Grad-CAM heatmap and save as PNG\n",
    "def generate_grad_cam_heatmaps(model, data, labels, save_dir, num_samples=3):\n",
    "    \"\"\"\n",
    "    Generate Grad-CAM heatmaps for the given data and save them as PNG files\n",
    "    in separate folders for positives and negatives.\n",
    "    \n",
    "    Args:\n",
    "        model (DeepScan): Trained model.\n",
    "        data (numpy array): Testing data.\n",
    "        labels (numpy array): Corresponding labels.\n",
    "        save_dir (str): Directory to save heatmaps.\n",
    "        num_samples (int): Number of heatmaps to display from positive and negative classes.\n",
    "    \"\"\"\n",
    "    pos_samples = []  # To store positive samples\n",
    "    neg_samples = []  # To store negative samples\n",
    "\n",
    "    for i, (x, label) in enumerate(zip(data, labels)):\n",
    "        # Expand dimensions to match model input shape (1, 1100, 1024)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        \n",
    "        # Generate Grad-CAM heatmap\n",
    "        heatmap = model.get_grad_cam_heatmap(x, class_index=np.argmax(label), layer_name='conv2d_1')\n",
    "\n",
    "        # Normalize heatmap to range [0, 1]\n",
    "        heatmap = np.maximum(heatmap, 0)\n",
    "        heatmap /= np.max(heatmap)\n",
    "\n",
    "        # Store heatmap based on class\n",
    "        class_label = np.argmax(label)  # 1 for positive, 0 for negative\n",
    "        if class_label == 1 and len(pos_samples) < num_samples:\n",
    "            pos_samples.append(heatmap)\n",
    "        elif class_label == 0 and len(neg_samples) < num_samples:\n",
    "            neg_samples.append(heatmap)\n",
    "\n",
    "        # Optionally, log progress\n",
    "        if i % 100 == 0:\n",
    "            print(f\"Processed {i}/{len(data)} samples\")\n",
    "\n",
    "        # Stop if we have enough positive and negative samples\n",
    "        if len(pos_samples) >= num_samples and len(neg_samples) >= num_samples:\n",
    "            break\n",
    "\n",
    "    # Display heatmaps\n",
    "    for idx, sample in enumerate(pos_samples):\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.imshow(sample, cmap='jet', interpolation='nearest')\n",
    "        plt.colorbar()\n",
    "        plt.title(f\"Positive Sample {idx + 1} - Grad-CAM Heatmap\")\n",
    "        plt.show()\n",
    "\n",
    "    for idx, sample in enumerate(neg_samples):\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.imshow(sample, cmap='jet', interpolation='nearest')\n",
    "        plt.colorbar()\n",
    "        plt.title(f\"Negative Sample {idx + 1} - Grad-CAM Heatmap\")\n",
    "        plt.show()\n",
    "\n",
    "    # Optionally, save the heatmaps to disk\n",
    "    for idx, sample in enumerate(pos_samples):\n",
    "        save_path = os.path.join(save_dir, \"Positives\", f\"positive_sample_{idx + 1}_heatmap.png\")\n",
    "        plt.imsave(save_path, sample, cmap='jet')\n",
    "\n",
    "    for idx, sample in enumerate(neg_samples):\n",
    "        save_path = os.path.join(save_dir, \"Negatives\", f\"negative_sample_{idx + 1}_heatmap.png\")\n",
    "        plt.imsave(save_path, sample, cmap='jet')\n",
    "\n",
    "# Generate Grad-CAM heatmaps for testing data\n",
    "if VALIDATION_MODE == \"independent\":\n",
    "    print(\"Generating Grad-CAM heatmaps for testing data...\")\n",
    "    generate_grad_cam_heatmaps(model, x_test, y_test, heatmap_save_dir)\n",
    "\n",
    "print(\"Heatmap generation complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "642ebfcd-eace-4b02-92c0-8dc478b41876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"deepscan\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_layer (InputLayer)       [(None, 1, 1100, 10  0           []                               \n",
      "                                24)]                                                              \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 1, 1097, 64)  262208      ['input_layer[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 1, 1093, 64)  524352      ['input_layer[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 1, 1085, 64)  1048640     ['input_layer[0][0]']            \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 1, 1096, 64)  0          ['conv2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 1, 1092, 64)  0          ['conv2d_2[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 1, 1084, 64)  0          ['conv2d_3[0][0]']               \n",
      "                                                                                                  \n",
      " global_pool_1 (GlobalAveragePo  (None, 64)          0           ['max_pooling2d_1[0][0]']        \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " global_pool_2 (GlobalAveragePo  (None, 64)          0           ['max_pooling2d_2[0][0]']        \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " global_pool_3 (GlobalAveragePo  (None, 64)          0           ['max_pooling2d_3[0][0]']        \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 192)          0           ['global_pool_1[0][0]',          \n",
      "                                                                  'global_pool_2[0][0]',          \n",
      "                                                                  'global_pool_3[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)            (None, 192)          0           ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 512)          98816       ['dropout_6[0][0]']              \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 2)            1026        ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,935,042\n",
      "Trainable params: 1,935,042\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/15\n",
      "290/290 [==============================] - 20s 67ms/step - loss: 0.1281 - accuracy: 0.9592\n",
      "Epoch 2/15\n",
      "290/290 [==============================] - 19s 67ms/step - loss: 0.0634 - accuracy: 0.9789\n",
      "Epoch 3/15\n",
      "290/290 [==============================] - 19s 67ms/step - loss: 0.0560 - accuracy: 0.9825\n",
      "Epoch 4/15\n",
      "290/290 [==============================] - 20s 67ms/step - loss: 0.0448 - accuracy: 0.9853\n",
      "Epoch 5/15\n",
      "290/290 [==============================] - 20s 68ms/step - loss: 0.0362 - accuracy: 0.9888\n",
      "Epoch 6/15\n",
      "290/290 [==============================] - 20s 68ms/step - loss: 0.0314 - accuracy: 0.9914\n",
      "Epoch 7/15\n",
      "290/290 [==============================] - 20s 68ms/step - loss: 0.0316 - accuracy: 0.9897\n",
      "Epoch 8/15\n",
      "290/290 [==============================] - 20s 69ms/step - loss: 0.0265 - accuracy: 0.9907\n",
      "Epoch 9/15\n",
      "290/290 [==============================] - 20s 69ms/step - loss: 0.0273 - accuracy: 0.9925\n",
      "Epoch 10/15\n",
      "290/290 [==============================] - 20s 67ms/step - loss: 0.0210 - accuracy: 0.9937\n",
      "Epoch 11/15\n",
      "290/290 [==============================] - 20s 68ms/step - loss: 0.0164 - accuracy: 0.9950\n",
      "Epoch 12/15\n",
      "290/290 [==============================] - 20s 68ms/step - loss: 0.0190 - accuracy: 0.9946\n",
      "Epoch 13/15\n",
      "290/290 [==============================] - 20s 67ms/step - loss: 0.0204 - accuracy: 0.9933\n",
      "Epoch 14/15\n",
      "290/290 [==============================] - 19s 67ms/step - loss: 0.0159 - accuracy: 0.9957\n",
      "Epoch 15/15\n",
      "290/290 [==============================] - 20s 68ms/step - loss: 0.0128 - accuracy: 0.9957\n",
      "Generating Grad-CAM heatmaps for testing data...\n",
      "Processed 0/1161 samples for Negatives\n",
      "Processed 100/1161 samples for Negatives\n",
      "Processed 200/1161 samples for Negatives\n",
      "Processed 300/1161 samples for Negatives\n",
      "Processed 400/1161 samples for Negatives\n",
      "Processed 500/1161 samples for Negatives\n",
      "Processed 600/1161 samples for Negatives\n",
      "Processed 700/1161 samples for Negatives\n",
      "Processed 800/1161 samples for Negatives\n",
      "Processed 900/1161 samples for Negatives\n",
      "Processed 1000/1161 samples for Positives\n",
      "Processed 1100/1161 samples for Negatives\n",
      "Heatmap generation complete!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# Define the directories to save the heatmaps\n",
    "heatmap_save_dir = \"C:/jupyter/Malik/SodiumTransporters/Code/HeatMaps_All\"\n",
    "os.makedirs(f\"{heatmap_save_dir}/Positives\", exist_ok=True)\n",
    "os.makedirs(f\"{heatmap_save_dir}/Negatives\", exist_ok=True)\n",
    "\n",
    "# Load your data (replace these lines with actual loading logic)\n",
    "x_train = x_train  # Replace with actual data loading\n",
    "y_train = y_train\n",
    "x_test = x_test\n",
    "y_test = y_test\n",
    "\n",
    "# Initialize DataGenerator with training data\n",
    "generator = DataGenerator(\n",
    "    data=x_train,\n",
    "    labels=y_train,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "# Initialize DeepScan model\n",
    "model = DeepScan(\n",
    "    window_sizes=WINDOW_SIZES,  # Replace with actual window sizes\n",
    "    num_filters=NUM_FILTER,    # Replace with actual number of filters\n",
    "    num_hidden=NUM_HIDDEN,     # Replace with actual number of hidden units\n",
    "    num_classes=NUM_CLASSES,   # Replace with actual number of classes\n",
    "    model_input_shape=(1, 1100, 1024)\n",
    ")\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Print model summary\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    generator,\n",
    "    epochs=EPOCHS,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Function to generate Grad-CAM heatmap and save as PNG\n",
    "def generate_grad_cam_heatmaps(model, data, labels, save_dir):\n",
    "    \"\"\"\n",
    "    Generate Grad-CAM heatmaps for the given data and save them as PNG files\n",
    "    in separate folders for positives and negatives.\n",
    "    \n",
    "    Args:\n",
    "        model (DeepScan): Trained model.\n",
    "        data (numpy array): Testing data.\n",
    "        labels (numpy array): Corresponding labels.\n",
    "        save_dir (str): Directory to save heatmaps.\n",
    "    \"\"\"\n",
    "    for i, (x, label) in enumerate(zip(data, labels)):\n",
    "        # Expand dimensions to match model input shape (1, 1100, 1024)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        \n",
    "        # Generate Grad-CAM heatmap\n",
    "        heatmap = model.get_grad_cam_heatmap(x, class_index=np.argmax(label), layer_name='conv2d_1')\n",
    "\n",
    "        # Normalize heatmap to range [0, 1]\n",
    "        heatmap = np.maximum(heatmap, 0)\n",
    "        heatmap /= np.max(heatmap)\n",
    "\n",
    "        # Convert heatmap to a format suitable for display\n",
    "        plt.imshow(heatmap, cmap='jet', interpolation='nearest')\n",
    "        plt.colorbar()\n",
    "\n",
    "        # Determine if the sample is positive or negative\n",
    "        class_label = np.argmax(label)  # 1 for positive, 0 for negative\n",
    "        label_class = \"Positives\" if class_label == 1 else \"Negatives\"\n",
    "\n",
    "        # Save heatmap as a PNG file\n",
    "        save_path = os.path.join(save_dir, label_class, f\"sample_{i}_heatmap.png\")\n",
    "        plt.savefig(save_path, bbox_inches='tight', pad_inches=0)\n",
    "        plt.close()  # Close the plot to free up memory\n",
    "\n",
    "        # Optionally, log progress\n",
    "        if i % 100 == 0:\n",
    "            print(f\"Processed {i}/{len(data)} samples for {label_class}\")\n",
    "\n",
    "# Generate Grad-CAM heatmaps for testing data\n",
    "if VALIDATION_MODE == \"independent\":\n",
    "    print(\"Generating Grad-CAM heatmaps for testing data...\")\n",
    "    generate_grad_cam_heatmaps(model, x_test, y_test, heatmap_save_dir)\n",
    "\n",
    "print(\"Heatmap generation complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564ceff9-acc3-46c0-bae4-74b70f56bf99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5c7c4413-5214-40fe-a707-6b4607499dee",
   "metadata": {},
   "source": [
    "## Select few image to display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0aa0a6ef-9be5-4457-be4c-14483b58d9d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heatmap figure saved at C:/jupyter/Malik/SodiumTransporters/Code/HeatMaps_All\\combined_heatmaps.png\n",
      "Heatmap generation complete!\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Define the directories where the heatmaps are saved\n",
    "heatmap_save_dir = \"C:/jupyter/Malik/SodiumTransporters/Code/HeatMaps_All\"\n",
    "positives_dir = os.path.join(heatmap_save_dir, \"Positives\")\n",
    "negatives_dir = os.path.join(heatmap_save_dir, \"Negatives\")\n",
    "\n",
    "# Function to randomly select and load heatmaps from the directory\n",
    "def load_random_heatmaps(directory, num_samples=3):\n",
    "    \"\"\"\n",
    "    Randomly select a number of heatmap files from the given directory.\n",
    "    \n",
    "    Args:\n",
    "        directory (str): The directory containing the heatmap files.\n",
    "        num_samples (int): The number of heatmap files to select.\n",
    "        \n",
    "    Returns:\n",
    "        list: A list of loaded heatmaps.\n",
    "    \"\"\"\n",
    "    # Get all the heatmap file names in the directory\n",
    "    heatmap_files = [f for f in os.listdir(directory) if f.endswith('.png')]\n",
    "    \n",
    "    # Randomly select 'num_samples' heatmaps\n",
    "    selected_files = random.sample(heatmap_files, num_samples)\n",
    "    \n",
    "    heatmaps = []\n",
    "    for file in selected_files:\n",
    "        # Load the heatmap image and append it to the list\n",
    "        heatmap_path = os.path.join(directory, file)\n",
    "        heatmap = plt.imread(heatmap_path)  # Read the image file\n",
    "        heatmaps.append(heatmap)\n",
    "    \n",
    "    return heatmaps\n",
    "\n",
    "# Function to plot and save the heatmaps in a single figure\n",
    "def plot_and_save_heatmaps(positives, negatives, save_dir):\n",
    "    \"\"\"\n",
    "    Plot and save a figure containing positive and negative heatmaps.\n",
    "    \n",
    "    Args:\n",
    "        positives (list): List of positive heatmaps to plot.\n",
    "        negatives (list): List of negative heatmaps to plot.\n",
    "        save_dir (str): Directory to save the figure.\n",
    "    \"\"\"\n",
    "    # Create a 2x3 grid (2 rows, 3 columns)\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(12, 8))  # Adjust size as needed\n",
    "    \n",
    "    # Plot heading for positives (Sodium Transporters)\n",
    "    axes[0, 0].text(0.5, 1.05, \"Sodium Transporters\", ha='center', va='bottom', fontsize=14, fontweight='bold')\n",
    "    for idx, sample in enumerate(positives):\n",
    "        ax = axes[0, idx]\n",
    "        ax.imshow(sample, cmap='jet', interpolation='nearest')\n",
    "        ax.axis('off')  # Hide axes for clarity\n",
    "\n",
    "    # Plot heading for negatives (Membrane Proteins)\n",
    "    axes[1, 0].text(0.5, 1.05, \"Membrane Proteins\", ha='center', va='bottom', fontsize=14, fontweight='bold')\n",
    "    for idx, sample in enumerate(negatives):\n",
    "        ax = axes[1, idx]\n",
    "        ax.imshow(sample, cmap='jet', interpolation='nearest')\n",
    "        ax.axis('off')  # Hide axes for clarity\n",
    "\n",
    "    # Save the figure at high resolution (300 DPI)\n",
    "    save_path = os.path.join(save_dir, \"combined_heatmaps.png\")\n",
    "    plt.tight_layout()  # Adjust layout to avoid overlap\n",
    "    plt.savefig(save_path, dpi=300)  # Save with high resolution\n",
    "    plt.close()  # Close the plot to free up memory\n",
    "\n",
    "    print(f\"Heatmap figure saved at {save_path}\")\n",
    "\n",
    "# Load three random positive and three random negative heatmaps\n",
    "positives = load_random_heatmaps(positives_dir, num_samples=3)\n",
    "negatives = load_random_heatmaps(negatives_dir, num_samples=3)\n",
    "\n",
    "# Plot and save the figure\n",
    "plot_and_save_heatmaps(positives, negatives, heatmap_save_dir)\n",
    "\n",
    "print(\"Heatmap generation complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716853d2-5c4b-42dc-ab4e-57fbdd71acac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
